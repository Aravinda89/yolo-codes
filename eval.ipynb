{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afe2164-a9d6-4e57-a270-8e5a4292233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6b9656-e766-4863-92a2-571d2e129329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"./runs/detect/train4/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c403a6-7ba3-4a17-9854-37e767e31055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.167 ðŸš€ Python-3.9.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 2.5Â±0.4 ms, read: 12.4Â±4.7 MB/s, size: 42.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/aravi/Documents/Projects/yolo-codes/data/traffic_light/val/labels.cache... 14 images, 0 backg\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         41      0.973      0.868      0.947      0.782\n",
      "                 Green          9         12      0.918      0.939       0.97       0.78\n",
      "                Yellow          9         12          1      0.904      0.952      0.837\n",
      "                   Red         12         17          1      0.761      0.921      0.727\n",
      "Speed: 0.5ms preprocess, 4.3ms inference, 0.0ms loss, 17.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Customize validation settings\n",
    "metrics = model.val(data=\"./dataset_custom.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e16120c1-42ab-4c2d-b43c-90a7a80fbb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.167 ðŸš€ Python-3.9.18 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 2.4Â±0.2 ms, read: 13.0Â±6.0 MB/s, size: 46.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/aravi/Documents/Projects/yolo-codes/data/traffic_light/val/labels.cache... 14 images, 0 backg\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         14         41      0.973      0.868      0.943      0.749\n",
      "                 Green          9         12      0.918      0.939       0.97      0.749\n",
      "                Yellow          9         12          1      0.904      0.933       0.81\n",
      "                   Red         12         17          1      0.761      0.925      0.688\n",
      "Speed: 3.3ms preprocess, 20.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
      "    Predicted  Green  Yellow   Red  background\n",
      "0       Green   12.0     1.0   0.0         0.0\n",
      "1      Yellow    0.0    10.0   0.0         3.0\n",
      "2         Red    0.0     1.0  15.0         2.0\n",
      "3  background    0.0     0.0   2.0         0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = model.val(data=\"./dataset_custom.yaml\", plots=True)\n",
    "print(results.confusion_matrix.to_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318faf5b-322e-4807-b2a6-72ed391afd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
